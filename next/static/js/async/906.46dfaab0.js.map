{"version":3,"file":"static/js/async/906.46dfaab0.js","sources":["../../../../../../packages/ai-engine/src/tauri-engine.ts"],"sourcesContent":["/**\n * Tauri Native ONNX Engine\n *\n * This engine uses Tauri's native Rust ONNX Runtime for AI analysis\n * in the desktop app with GPU acceleration via CUDA, CoreML, or DirectML.\n *\n * IMPORTANT: This module uses ONLY the global window.__TAURI__ object\n * and does NOT use any dynamic imports to avoid bundler issues with workers.\n */\n\nimport type { SignMap } from '@kaya/goboard';\nimport {\n  Engine,\n  type BaseEngineConfig,\n  type EngineAnalysisOptions,\n  type EngineCapabilities,\n} from './base-engine';\nimport type { AnalysisResult, MoveSuggestion } from './types';\n\n/**\n * Progress info for model upload\n */\nexport interface UploadProgress {\n  /** Current stage: 'checking-cache' | 'uploading' | 'initializing' */\n  stage: 'checking-cache' | 'uploading' | 'initializing';\n  /** Progress percentage (0-100) */\n  progress: number;\n  /** Human-readable message */\n  message: string;\n}\n\n/**\n * Execution provider preference for native ONNX Runtime\n */\nexport type ExecutionProviderPreference = 'auto' | 'cuda' | 'coreml' | 'directml' | 'cpu';\n\n/**\n * Information about an execution provider\n */\nexport interface ExecutionProviderInfo {\n  /** Provider name */\n  name: string;\n  /** Whether it uses GPU acceleration */\n  isGpu: boolean;\n  /** Human-readable description */\n  description: string;\n}\n\nexport interface TauriEngineConfig extends BaseEngineConfig {\n  /** ArrayBuffer of the ONNX model (will be uploaded in chunks to Rust) */\n  modelBuffer?: ArrayBuffer;\n\n  /** Path to the ONNX model file on disk */\n  modelPath?: string;\n\n  /** Model ID for caching (e.g., model name or hash) */\n  modelId?: string;\n\n  /** Enable debug logging */\n  debug?: boolean;\n\n  /** Callback for upload progress updates */\n  onProgress?: (progress: UploadProgress) => void;\n\n  /**\n   * Execution provider preference for native ONNX Runtime\n   * - 'auto': Best available (GPU first, then CPU)\n   * - 'cuda': NVIDIA CUDA (requires CUDA toolkit)\n   * - 'coreml': Apple CoreML (macOS/iOS)\n   * - 'directml': Windows DirectML\n   * - 'cpu': CPU only\n   */\n  executionProvider?: ExecutionProviderPreference;\n}\n\n/**\n * History move entry for the Tauri backend\n */\ninterface HistoryMove {\n  color: number;\n  x: number;\n  y: number;\n}\n\n/**\n * Analysis options for the Tauri backend\n */\ninterface TauriAnalysisOptions {\n  komi: number;\n  nextToPlay?: string;\n  history: HistoryMove[];\n}\n\n/**\n * Batch input for the Tauri backend\n */\ninterface TauriBatchInput {\n  signMap: number[][];\n  options: TauriAnalysisOptions;\n}\n\n/**\n * Type for the Tauri invoke function\n */\ntype TauriInvokeFn = <T>(cmd: string, args?: Record<string, unknown>) => Promise<T>;\n\n/**\n * Check if we're running in a Tauri environment\n * This checks for the global Tauri object without any dynamic imports\n */\nexport function isTauriEnvironment(): boolean {\n  try {\n    if (typeof window === 'undefined' || window === null) {\n      return false;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const w = window as any;\n    return '__TAURI_INTERNALS__' in w || '__TAURI__' in w;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Get the Tauri invoke function from the global window object\n * This does NOT use dynamic imports to avoid bundler issues\n */\nfunction getTauriInvoke(): TauriInvokeFn | null {\n  if (!isTauriEnvironment()) {\n    return null;\n  }\n\n  try {\n    const w = window as Record<string, any>;\n\n    // Tauri v2 with withGlobalTauri: true\n    if (w.__TAURI__?.core?.invoke) {\n      return w.__TAURI__.core.invoke;\n    }\n\n    // Tauri v2 internals\n    if (w.__TAURI_INTERNALS__?.invoke) {\n      return w.__TAURI_INTERNALS__.invoke;\n    }\n\n    return null;\n  } catch {\n    return null;\n  }\n}\n\n// Chunk size for model upload (1MB per chunk for responsive UI)\n// Smaller chunks = more responsive UI during upload\nconst CHUNK_SIZE = 1 * 1024 * 1024;\n\n/**\n * Convert a chunk of bytes to base64 string efficiently\n */\nfunction chunkToBase64(chunk: Uint8Array): string {\n  // Use btoa with smaller sub-chunks to avoid call stack issues\n  const BATCH_SIZE = 32768;\n  let binary = '';\n  for (let i = 0; i < chunk.length; i += BATCH_SIZE) {\n    const end = Math.min(i + BATCH_SIZE, chunk.length);\n    const subChunk = chunk.subarray(i, end);\n    for (let j = 0; j < subChunk.length; j++) {\n      binary += String.fromCharCode(subChunk[j]);\n    }\n  }\n  return btoa(binary);\n}\n\n/**\n * Yield to the event loop to keep UI responsive\n */\nfunction yieldToUI(): Promise<void> {\n  return new Promise(resolve => setTimeout(resolve, 0));\n}\n\nexport class TauriEngine extends Engine {\n  private debugEnabled = false;\n  private modelBuffer?: ArrayBuffer;\n  private modelPath?: string;\n  private modelId?: string;\n  private invoke: TauriInvokeFn | null = null;\n  private onProgress?: (progress: UploadProgress) => void;\n  private executionProvider: ExecutionProviderPreference;\n\n  constructor(config: TauriEngineConfig = {}) {\n    super(config);\n    this.debugEnabled = Boolean(config.debug);\n    this.modelBuffer = config.modelBuffer;\n    this.modelPath = config.modelPath;\n    this.modelId = config.modelId;\n    this.onProgress = config.onProgress;\n    this.executionProvider = config.executionProvider ?? 'auto';\n\n    // Get invoke function immediately in constructor\n    this.invoke = getTauriInvoke();\n  }\n\n  private reportProgress(stage: UploadProgress['stage'], progress: number, message: string): void {\n    this.onProgress?.({ stage, progress, message });\n  }\n\n  private debugLog(message: string, payload?: Record<string, unknown>): void {\n    if (!this.debugEnabled) return;\n    if (payload) {\n      console.log('[TauriEngine][debug]', message, payload);\n    } else {\n      console.log('[TauriEngine][debug]', message);\n    }\n  }\n\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    if (!this.invoke) {\n      throw new Error('TauriEngine can only be used in a Tauri environment');\n    }\n\n    try {\n      const initStart = performance.now();\n\n      // Set the execution provider preference before loading the model\n      await this.invoke('onnx_set_provider_preference', { preference: this.executionProvider });\n\n      // If we have a modelId, check if it's already cached\n      if (this.modelId) {\n        this.reportProgress('checking-cache', 0, 'Checking for cached model...');\n\n        const cachedPath = await this.invoke<string | null>('onnx_get_cached_model', {\n          modelId: this.modelId,\n        });\n\n        if (cachedPath) {\n          this.reportProgress('initializing', 50, 'Loading cached model...');\n          await this.invoke('onnx_initialize_from_path', { modelPath: cachedPath });\n          this.reportProgress('initializing', 100, 'Ready');\n\n          // Log model loaded info\n          const initTime = performance.now() - initStart;\n          const providerInfo = await this.getProviderInfo();\n          const backend = providerInfo?.isGpu ? 'NATIVE/GPU' : 'NATIVE/CPU';\n          const provider = providerInfo?.name ? ` (${providerInfo.name})` : '';\n          const timeStr =\n            initTime >= 1000 ? `${(initTime / 1000).toFixed(1)}s` : `${initTime.toFixed(0)}ms`;\n          console.log(`[AI] Model loaded: ${backend}${provider} in ${timeStr}`);\n\n          this.initialized = true;\n          return;\n        }\n      }\n\n      if (this.modelBuffer) {\n        const sizeMB = (this.modelBuffer.byteLength / 1024 / 1024).toFixed(1);\n        const totalChunks = Math.ceil(this.modelBuffer.byteLength / CHUNK_SIZE);\n\n        this.reportProgress('uploading', 0, `Preparing to upload ${sizeMB}MB model...`);\n\n        // Start the chunked upload\n        const uploadStart = performance.now();\n        await this.invoke('onnx_start_upload');\n\n        // Upload chunks with base64 encoding (more efficient than JSON arrays)\n        const bytes = new Uint8Array(this.modelBuffer);\n        for (let i = 0; i < totalChunks; i++) {\n          const start = i * CHUNK_SIZE;\n          const end = Math.min(start + CHUNK_SIZE, bytes.length);\n          const chunk = bytes.subarray(start, end);\n\n          // Convert to base64 and upload\n          const chunkBase64 = chunkToBase64(chunk);\n          await this.invoke('onnx_upload_chunk', { chunkBase64 });\n\n          // Yield to UI every chunk to stay responsive\n          await yieldToUI();\n\n          // Report progress on every chunk for smooth UI updates\n          const progressPct = Math.round(((i + 1) / totalChunks) * 100);\n          const uploadedMB = (((i + 1) * CHUNK_SIZE) / 1024 / 1024).toFixed(0);\n          this.reportProgress(\n            'uploading',\n            progressPct,\n            `Uploading model: ${uploadedMB}/${sizeMB}MB (${progressPct}%)`\n          );\n        }\n\n        const uploadTime = performance.now() - uploadStart;\n        this.debugLog('Upload complete', { uploadTimeMs: uploadTime, totalChunks });\n\n        // Finish upload and initialize engine (with optional caching)\n        this.reportProgress('initializing', 100, 'Initializing ONNX engine...');\n        const engineStart = performance.now();\n        await this.invoke('onnx_finish_upload', { modelId: this.modelId ?? null });\n        const engineTime = performance.now() - engineStart;\n        this.debugLog('Engine initialized', { engineTimeMs: engineTime });\n\n        this.reportProgress('initializing', 100, 'Ready');\n      } else if (this.modelPath) {\n        // Initialize from file path directly\n        this.reportProgress('initializing', 50, 'Loading model from file...');\n        this.debugLog('Initializing from path', { path: this.modelPath });\n        await this.invoke('onnx_initialize_from_path', { modelPath: this.modelPath });\n        this.reportProgress('initializing', 100, 'Ready');\n      } else {\n        throw new Error('No model provided (need modelBuffer or modelPath)');\n      }\n\n      const initTime = performance.now() - initStart;\n\n      // Log model loaded info (single consistent message)\n      const providerInfo = await this.getProviderInfo();\n      const backend = providerInfo?.isGpu ? 'NATIVE/GPU' : 'NATIVE/CPU';\n      const provider = providerInfo?.name ? ` (${providerInfo.name})` : '';\n      const timeStr =\n        initTime >= 1000 ? `${(initTime / 1000).toFixed(1)}s` : `${initTime.toFixed(0)}ms`;\n      console.log(`[AI] Model loaded: ${backend}${provider} in ${timeStr}`);\n\n      this.initialized = true;\n    } catch (e) {\n      console.error('[TauriEngine] Failed to initialize:', e);\n      throw e;\n    }\n  }\n\n  getCapabilities(): EngineCapabilities {\n    return {\n      name: 'KataGo (Native ONNX)',\n      version: '1.0.0',\n      supportedBoardSizes: [],\n      supportsParallel: true,\n      providesPV: false,\n      providesWinRate: true,\n      providesScoreLead: true,\n      metadata: {\n        backend: 'native',\n        runtime: 'ort',\n      },\n    };\n  }\n\n  protected async analyzePosition(\n    signMap: SignMap,\n    options: EngineAnalysisOptions\n  ): Promise<AnalysisResult> {\n    if (!this.invoke) {\n      throw new Error('TauriEngine can only be used in a Tauri environment');\n    }\n\n    const analysisStart = performance.now();\n\n    // Convert SignMap to number[][] for Rust\n    const signMapArray = signMap.map(row => row.map(s => s as number));\n\n    // Prepare options for Rust\n    const tauriOptions: TauriAnalysisOptions = {\n      komi: options.komi ?? 7.5,\n      nextToPlay: options.nextToPlay,\n      history: this.convertHistory(options.history),\n    };\n\n    this.debugLog('Analyzing position', {\n      boardSize: signMap.length,\n      nextToPlay: tauriOptions.nextToPlay,\n      historyLength: tauriOptions.history.length,\n    });\n\n    const inferenceStart = performance.now();\n    const result = await this.invoke<AnalysisResult>('onnx_analyze', {\n      signMap: signMapArray,\n      options: tauriOptions,\n    });\n    const inferenceTime = performance.now() - inferenceStart;\n\n    const totalTime = performance.now() - analysisStart;\n    this.debugLog('Analysis complete', {\n      totalTimeMs: totalTime,\n      inferenceTimeMs: inferenceTime,\n    });\n\n    return result;\n  }\n\n  async analyzeBatch(\n    inputs: { signMap: SignMap; options?: EngineAnalysisOptions }[]\n  ): Promise<AnalysisResult[]> {\n    if (!this.initialized) {\n      await this.initialize();\n    }\n\n    if (inputs.length === 0) return [];\n\n    if (!this.invoke) {\n      throw new Error('TauriEngine can only be used in a Tauri environment');\n    }\n\n    const batchStart = performance.now();\n\n    // Check cache first\n    const results: (AnalysisResult | null)[] = new Array(inputs.length).fill(null);\n    const uncachedInputs: { index: number; input: TauriBatchInput }[] = [];\n\n    const useCache = this.config.enableCache;\n    for (let i = 0; i < inputs.length; i++) {\n      const { signMap, options = {} } = inputs[i];\n      if (useCache) {\n        const cacheKey = this.getCacheKey(signMap, options);\n        const cached = this.cache.get(cacheKey);\n        if (cached) {\n          results[i] = cached;\n          continue;\n        }\n      }\n\n      // Prepare batch input for Rust\n      uncachedInputs.push({\n        index: i,\n        input: {\n          signMap: signMap.map(row => row.map(s => s as number)),\n          options: {\n            komi: options.komi ?? 7.5,\n            nextToPlay: options.nextToPlay,\n            history: this.convertHistory(options.history),\n          },\n        },\n      });\n    }\n\n    if (uncachedInputs.length === 0) {\n      this.debugLog('Batch resolved from cache', { count: inputs.length });\n      return results as AnalysisResult[];\n    }\n\n    this.debugLog('Running batch inference', {\n      total: inputs.length,\n      uncached: uncachedInputs.length,\n    });\n\n    const inferenceStart = performance.now();\n    const batchInputs = uncachedInputs.map(u => u.input);\n    const batchResults = await this.invoke<AnalysisResult[]>('onnx_analyze_batch', {\n      inputs: batchInputs,\n    });\n    const inferenceTime = performance.now() - inferenceStart;\n\n    // Store in cache and merge results\n    for (let i = 0; i < uncachedInputs.length; i++) {\n      const { index, input } = uncachedInputs[i];\n      const result = batchResults[i];\n      results[index] = result;\n\n      if (useCache) {\n        const { signMap, options = {} } = inputs[index];\n        const cacheKey = this.getCacheKey(signMap, options);\n        this.cache.set(cacheKey, result);\n\n        // Evict oldest if cache is full\n        if (this.cache.size > (this.config.maxCacheSize ?? 1000)) {\n          const firstKey = this.cache.keys().next().value;\n          if (firstKey) this.cache.delete(firstKey);\n        }\n      }\n    }\n\n    const totalTime = performance.now() - batchStart;\n    const msPerPos = totalTime / uncachedInputs.length;\n    this.debugLog('Batch analysis complete', {\n      positions: uncachedInputs.length,\n      totalTimeMs: totalTime,\n      msPerPos,\n      inferenceTimeMs: inferenceTime,\n    });\n\n    return results as AnalysisResult[];\n  }\n\n  async dispose(): Promise<void> {\n    if (this.invoke) {\n      try {\n        await this.invoke('onnx_dispose');\n      } catch (e) {\n        console.warn('[TauriEngine] Failed to dispose:', e);\n      }\n    }\n    await super.dispose();\n  }\n\n  /**\n   * Convert history from the EngineAnalysisOptions format to TauriAnalysisOptions format\n   */\n  private convertHistory(history?: { color: number; x: number; y: number }[]): HistoryMove[] {\n    if (!history) return [];\n    return history.map(m => ({\n      color: m.color,\n      x: m.x,\n      y: m.y,\n    }));\n  }\n\n  /**\n   * Get the current execution provider info from the initialized engine\n   */\n  async getProviderInfo(): Promise<ExecutionProviderInfo | null> {\n    if (!this.invoke) return null;\n    try {\n      return await this.invoke<ExecutionProviderInfo | null>('onnx_get_provider_info');\n    } catch {\n      return null;\n    }\n  }\n\n  /**\n   * Get available execution providers for this platform\n   */\n  static async getAvailableProviders(): Promise<ExecutionProviderInfo[]> {\n    const invoke = getTauriInvoke();\n    if (!invoke) return [];\n    try {\n      return await invoke<ExecutionProviderInfo[]>('onnx_get_available_providers');\n    } catch {\n      return [];\n    }\n  }\n}\n"],"names":["getTauriInvoke","isTauriEnvironment","window","w","_w___TAURI___core","_w___TAURI_INTERNALS__","TauriEngine","Engine","stage","progress","message","_this","payload","console","Error","initStart","performance","cachedPath","initTime","providerInfo","backend","provider","timeStr","sizeMB","totalChunks","Math","uploadStart","bytes","Uint8Array","i","start","end","chunk","chunkBase64","chunkToBase64","binary","subChunk","j","String","btoa","Promise","resolve","setTimeout","progressPct","uploadedMB","uploadTime","engineStart","engineTime","e","signMap","options","analysisStart","signMapArray","row","s","tauriOptions","inferenceStart","result","inferenceTime","totalTime","inputs","batchStart","results","Array","uncachedInputs","useCache","cacheKey","cached","batchInputs","u","batchResults","index","input","firstKey","msPerPos","history","m","invoke","config","Boolean"],"mappings":"oJA+HA,SAASA,IACP,GAAI,CAACC,AAlBA,WACL,GAAI,CACF,GAAI,AAAkB,aAAlB,OAAOC,QAA0BA,AAAW,OAAXA,OACnC,MAAO,GAGT,IAAMC,EAAID,OACV,MAAO,wBAAyBC,GAAK,cAAeA,CACtD,CAAE,KAAM,CACN,MAAO,EACT,CACF,IAQI,OAAO,KAGT,GAAI,C,IAIEC,EAAAA,EAKAC,EARJ,IAAMF,EAAID,OAGV,SAAIE,CAAAA,EAAAA,EAAE,SAAS,AAAD,GAAVA,MAAAA,CAAAA,EAAAA,EAAa,IAAI,AAAD,EAAhBA,KAAAA,EAAAA,EAAmB,MAAM,CAC3B,OAAOD,EAAE,SAAS,CAAC,IAAI,CAAC,MAAM,CAIhC,GAAI,MAAAE,CAAAA,EAAAA,EAAE,mBAAmB,AAAD,EAApBA,KAAAA,EAAAA,EAAuB,MAAM,CAC/B,OAAOF,EAAE,mBAAmB,CAAC,MAAM,CAGrC,OAAO,IACT,CAAE,KAAM,CACN,OAAO,IACT,CACF,CA8BO,MAAMG,UAAoBC,EAAAA,CAAMA,CAsB7B,eAAeC,CAA8B,CAAEC,CAAgB,CAAEC,CAAe,CAAQ,C,IAC9FC,C,OAAAA,CAAAA,EAAAA,AAAAA,IAAI,CAAC,UAAU,AAAD,GAAdA,EAAAA,IAAAA,CAAAA,IAAI,CAAc,CAAEH,MAAAA,EAAOC,SAAAA,EAAUC,QAAAA,CAAQ,EAC/C,CAEQ,SAASA,CAAe,CAAEE,CAAiC,CAAQ,CACpE,IAAI,CAAC,YAAY,GAClBA,EACFC,QAAQ,GAAG,CAAC,uBAAwBH,EAASE,GAE7CC,QAAQ,GAAG,CAAC,uBAAwBH,GAExC,CAEA,MAAM,YAA4B,CAChC,IAAI,IAAI,CAAC,WAAW,EAEpB,GAAI,CAAC,IAAI,CAAC,MAAM,CACd,MAAM,AAAII,MAAM,uDAGlB,GAAI,CACF,IAAMC,EAAYC,YAAY,GAAG,GAMjC,GAHA,MAAM,IAAI,CAAC,MAAM,CAAC,+BAAgC,CAAE,WAAY,IAAI,CAAC,iBAAiB,AAAC,GAGnF,IAAI,CAAC,OAAO,CAAE,CAChB,IAAI,CAAC,cAAc,CAAC,iBAAkB,EAAG,gCAEzC,IAAMC,EAAa,MAAM,IAAI,CAAC,MAAM,CAAgB,wBAAyB,CAC3E,QAAS,IAAI,CAAC,OAAO,AACvB,GAEA,GAAIA,EAAY,CACd,IAAI,CAAC,cAAc,CAAC,eAAgB,GAAI,2BACxC,MAAM,IAAI,CAAC,MAAM,CAAC,4BAA6B,CAAE,UAAWA,CAAW,GACvE,IAAI,CAAC,cAAc,CAAC,eAAgB,IAAK,SAGzC,IAAMC,EAAWF,YAAY,GAAG,GAAKD,EAC/BI,EAAe,MAAM,IAAI,CAAC,eAAe,GACzCC,EAAUD,AAAAA,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAc,KAAK,AAAD,EAAI,aAAe,aAC/CE,EAAWF,AAAAA,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAc,IAAI,AAAD,EAAI,CAAC,EAAE,EAAEA,EAAa,IAAI,CAAC,CAAC,CAAC,CAAG,GAC5DG,EACJJ,GAAY,IAAO,CAAC,EAAGA,AAAAA,CAAAA,EAAW,GAAG,EAAG,OAAO,CAAC,GAAG,CAAC,CAAC,CAAG,CAAC,EAAEA,EAAS,OAAO,CAAC,GAAG,EAAE,CAAC,CACpFL,QAAQ,GAAG,CAAC,CAAC,mBAAmB,EAAEO,EAAQ,EAAEC,EAAS,IAAI,EAAEC,EAAQ,CAAC,EAEpE,IAAI,CAAC,WAAW,CAAG,GACnB,MACF,CACF,CAEA,GAAI,IAAI,CAAC,WAAW,CAAE,CACpB,IAAMC,EAAU,KAAI,CAAC,WAAW,CAAC,UAAU,CAAG,KAAO,IAAG,EAAG,OAAO,CAAC,GAC7DC,EAAcC,KAAK,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,UAAU,CAvG9C,SAyGX,IAAI,CAAC,cAAc,CAAC,YAAa,EAAG,CAAC,oBAAoB,EAAEF,EAAO,WAAW,CAAC,EAG9E,IAAMG,EAAcV,YAAY,GAAG,EACnC,OAAM,IAAI,CAAC,MAAM,CAAC,qBAGlB,IAAMW,EAAQ,IAAIC,WAAW,IAAI,CAAC,WAAW,EAC7C,IAAK,IAAIC,EAAI,EAAGA,EAAIL,EAAaK,IAAK,CACpC,IAAMC,EAAQD,AAlHL,QAkHKA,EACRE,EAAMN,KAAK,GAAG,CAACK,EAnHZ,QAmHgCH,EAAM,MAAM,EAC/CK,EAAQL,EAAM,QAAQ,CAACG,EAAOC,GAG9BE,EAAcC,AAlH9B,SAAuBF,CAAiB,EAGtC,IAAIG,EAAS,GACb,IAAK,IAAIN,EAAI,EAAGA,EAAIG,EAAM,MAAM,CAAEH,GAFf,MAEgC,CACjD,IAAME,EAAMN,KAAK,GAAG,CAACI,EAHJ,MAGoBG,EAAM,MAAM,EAC3CI,EAAWJ,EAAM,QAAQ,CAACH,EAAGE,GACnC,IAAK,IAAIM,EAAI,EAAGA,EAAID,EAAS,MAAM,CAAEC,IACnCF,GAAUG,OAAO,YAAY,CAACF,CAAQ,CAACC,EAAE,CAE7C,CACA,OAAOE,KAAKJ,EACd,EAsG4CH,EAClC,OAAM,IAAI,CAAC,MAAM,CAAC,oBAAqB,CAAEC,YAAAA,CAAY,GAGrD,MApGD,IAAIO,QAAQC,AAAAA,GAAWC,WAAWD,EAAS,IAuG1C,IAAME,EAAclB,KAAK,KAAK,CAAGI,AAAAA,CAAAA,EAAI,GAAKL,EAAe,KACnDoB,EAAc,AAAEf,CAAAA,CAAAA,EAAI,GA/HjB,QA+HoC,KAAO,IAAG,EAAG,OAAO,CAAC,GAClE,IAAI,CAAC,cAAc,CACjB,YACAc,EACA,CAAC,iBAAiB,EAAEC,EAAW,CAAC,EAAErB,EAAO,IAAI,EAAEoB,EAAY,EAAE,CAAC,CAElE,CAEA,IAAME,EAAa7B,YAAY,GAAG,GAAKU,EACvC,IAAI,CAAC,QAAQ,CAAC,kBAAmB,CAAE,aAAcmB,EAAYrB,YAAAA,CAAY,GAGzE,IAAI,CAAC,cAAc,CAAC,eAAgB,IAAK,+BACzC,IAAMsB,EAAc9B,YAAY,GAAG,EACnC,OAAM,IAAI,CAAC,MAAM,CAAC,qBAAsB,CAAE,QAAS,IAAI,CAAC,OAAO,EAAI,IAAK,GACxE,IAAM+B,EAAa/B,YAAY,GAAG,GAAK8B,EACvC,IAAI,CAAC,QAAQ,CAAC,qBAAsB,CAAE,aAAcC,CAAW,GAE/D,IAAI,CAAC,cAAc,CAAC,eAAgB,IAAK,QAC3C,MAAO,GAAI,IAAI,CAAC,SAAS,CAEvB,IAAI,CAAC,cAAc,CAAC,eAAgB,GAAI,8BACxC,IAAI,CAAC,QAAQ,CAAC,yBAA0B,CAAE,KAAM,IAAI,CAAC,SAAS,AAAC,GAC/D,MAAM,IAAI,CAAC,MAAM,CAAC,4BAA6B,CAAE,UAAW,IAAI,CAAC,SAAS,AAAC,GAC3E,IAAI,CAAC,cAAc,CAAC,eAAgB,IAAK,cAEzC,MAAM,AAAIjC,MAAM,qDAGlB,IAAMI,EAAWF,YAAY,GAAG,GAAKD,EAG/BI,EAAe,MAAM,IAAI,CAAC,eAAe,GACzCC,EAAUD,AAAAA,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAc,KAAK,AAAD,EAAI,aAAe,aAC/CE,EAAWF,AAAAA,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAc,IAAI,AAAD,EAAI,CAAC,EAAE,EAAEA,EAAa,IAAI,CAAC,CAAC,CAAC,CAAG,GAC5DG,EACJJ,GAAY,IAAO,CAAC,EAAGA,AAAAA,CAAAA,EAAW,GAAG,EAAG,OAAO,CAAC,GAAG,CAAC,CAAC,CAAG,CAAC,EAAEA,EAAS,OAAO,CAAC,GAAG,EAAE,CAAC,CACpFL,QAAQ,GAAG,CAAC,CAAC,mBAAmB,EAAEO,EAAQ,EAAEC,EAAS,IAAI,EAAEC,EAAQ,CAAC,EAEpE,IAAI,CAAC,WAAW,CAAG,EACrB,CAAE,MAAO0B,EAAG,CAEV,MADAnC,QAAQ,KAAK,CAAC,sCAAuCmC,GAC/CA,CACR,EACF,CAEA,iBAAsC,CACpC,MAAO,CACL,KAAM,uBACN,QAAS,QACT,oBAAqB,EAAE,CACvB,iBAAkB,GAClB,WAAY,GACZ,gBAAiB,GACjB,kBAAmB,GACnB,SAAU,CACR,QAAS,SACT,QAAS,KACX,CACF,CACF,CAEA,MAAgB,gBACdC,CAAgB,CAChBC,CAA8B,CACL,CACzB,GAAI,CAAC,IAAI,CAAC,MAAM,CACd,MAAM,AAAIpC,MAAM,uDAGlB,IAAMqC,EAAgBnC,YAAY,GAAG,GAG/BoC,EAAeH,EAAQ,GAAG,CAACI,AAAAA,GAAOA,EAAI,GAAG,CAACC,AAAAA,GAAKA,IAG/CC,EAAqC,CACzC,KAAML,EAAQ,IAAI,EAAI,IACtB,WAAYA,EAAQ,UAAU,CAC9B,QAAS,IAAI,CAAC,cAAc,CAACA,EAAQ,OAAO,CAC9C,EAEA,IAAI,CAAC,QAAQ,CAAC,qBAAsB,CAClC,UAAWD,EAAQ,MAAM,CACzB,WAAYM,EAAa,UAAU,CACnC,cAAeA,EAAa,OAAO,CAAC,MAAM,AAC5C,GAEA,IAAMC,EAAiBxC,YAAY,GAAG,GAChCyC,EAAS,MAAM,IAAI,CAAC,MAAM,CAAiB,eAAgB,CAC/D,QAASL,EACT,QAASG,CACX,GACMG,EAAgB1C,YAAY,GAAG,GAAKwC,EAEpCG,EAAY3C,YAAY,GAAG,GAAKmC,EAMtC,OALA,IAAI,CAAC,QAAQ,CAAC,oBAAqB,CACjC,YAAaQ,EACb,gBAAiBD,CACnB,GAEOD,CACT,CAEA,MAAM,aACJG,CAA+D,CACpC,CAK3B,GAJI,AAAC,IAAI,CAAC,WAAW,EACnB,MAAM,IAAI,CAAC,UAAU,GAGnBA,AAAkB,IAAlBA,EAAO,MAAM,CAAQ,MAAO,EAAE,CAElC,GAAI,CAAC,IAAI,CAAC,MAAM,CACd,MAAM,AAAI9C,MAAM,uDAGlB,IAAM+C,EAAa7C,YAAY,GAAG,GAG5B8C,EAAqC,AAAIC,MAAMH,EAAO,MAAM,EAAE,IAAI,CAAC,MACnEI,EAA8D,EAAE,CAEhEC,EAAW,IAAI,CAAC,MAAM,CAAC,WAAW,CACxC,IAAK,IAAIpC,EAAI,EAAGA,EAAI+B,EAAO,MAAM,CAAE/B,IAAK,CACtC,GAAM,CAAEoB,QAAAA,CAAO,CAAEC,QAAAA,EAAU,CAAC,CAAC,CAAE,CAAGU,CAAM,CAAC/B,EAAE,CAC3C,GAAIoC,EAAU,CACZ,IAAMC,EAAW,IAAI,CAAC,WAAW,CAACjB,EAASC,GACrCiB,EAAS,IAAI,CAAC,KAAK,CAAC,GAAG,CAACD,GAC9B,GAAIC,EAAQ,CACVL,CAAO,CAACjC,EAAE,CAAGsC,EACb,QACF,CACF,CAGAH,EAAe,IAAI,CAAC,CAClB,MAAOnC,EACP,MAAO,CACL,QAASoB,EAAQ,GAAG,CAACI,AAAAA,GAAOA,EAAI,GAAG,CAACC,AAAAA,GAAKA,IACzC,QAAS,CACP,KAAMJ,EAAQ,IAAI,EAAI,IACtB,WAAYA,EAAQ,UAAU,CAC9B,QAAS,IAAI,CAAC,cAAc,CAACA,EAAQ,OAAO,CAC9C,CACF,CACF,EACF,CAEA,GAAIc,AAA0B,IAA1BA,EAAe,MAAM,CAEvB,OADA,IAAI,CAAC,QAAQ,CAAC,4BAA6B,CAAE,MAAOJ,EAAO,MAAM,AAAC,GAC3DE,EAGT,IAAI,CAAC,QAAQ,CAAC,0BAA2B,CACvC,MAAOF,EAAO,MAAM,CACpB,SAAUI,EAAe,MAAM,AACjC,GAEA,IAAMR,EAAiBxC,YAAY,GAAG,GAChCoD,EAAcJ,EAAe,GAAG,CAACK,AAAAA,GAAKA,EAAE,KAAK,EAC7CC,EAAe,MAAM,IAAI,CAAC,MAAM,CAAmB,qBAAsB,CAC7E,OAAQF,CACV,GACMV,EAAgB1C,YAAY,GAAG,GAAKwC,EAG1C,IAAK,IAAI3B,EAAI,EAAGA,EAAImC,EAAe,MAAM,CAAEnC,IAAK,CAC9C,GAAM,CAAE0C,MAAAA,CAAK,CAAEC,MAAAA,CAAK,CAAE,CAAGR,CAAc,CAACnC,EAAE,CACpC4B,EAASa,CAAY,CAACzC,EAAE,CAG9B,GAFAiC,CAAO,CAACS,EAAM,CAAGd,EAEbQ,EAAU,CACZ,GAAM,CAAEhB,QAAAA,CAAO,CAAEC,QAAAA,EAAU,CAAC,CAAC,CAAE,CAAGU,CAAM,CAACW,EAAM,CACzCL,EAAW,IAAI,CAAC,WAAW,CAACjB,EAASC,GAI3C,GAHA,IAAI,CAAC,KAAK,CAAC,GAAG,CAACgB,EAAUT,GAGrB,IAAI,CAAC,KAAK,CAAC,IAAI,CAAI,KAAI,CAAC,MAAM,CAAC,YAAY,EAAI,GAAG,EAAI,CACxD,IAAMgB,EAAW,IAAI,CAAC,KAAK,CAAC,IAAI,GAAG,IAAI,GAAG,KAAK,AAC3CA,CAAAA,GAAU,IAAI,CAAC,KAAK,CAAC,MAAM,CAACA,EAClC,CACF,CACF,CAEA,IAAMd,EAAY3C,YAAY,GAAG,GAAK6C,EAChCa,EAAWf,EAAYK,EAAe,MAAM,CAQlD,OAPA,IAAI,CAAC,QAAQ,CAAC,0BAA2B,CACvC,UAAWA,EAAe,MAAM,CAChC,YAAaL,EACbe,SAAAA,EACA,gBAAiBhB,CACnB,GAEOI,CACT,CAEA,MAAM,SAAyB,CAC7B,GAAI,IAAI,CAAC,MAAM,CACb,GAAI,CACF,MAAM,IAAI,CAAC,MAAM,CAAC,eACpB,CAAE,MAAOd,EAAG,CACVnC,QAAQ,IAAI,CAAC,mCAAoCmC,EACnD,CAEF,MAAM,KAAK,CAAC,SACd,CAKQ,eAAe2B,CAAmD,CAAiB,QACzF,AAAKA,EACEA,EAAQ,GAAG,CAACC,AAAAA,GAAM,EACvB,MAAOA,EAAE,KAAK,CACd,EAAGA,EAAE,CAAC,CACN,EAAGA,EAAE,CAAC,AACR,IALqB,EAAE,AAMzB,CAKA,MAAM,iBAAyD,CAC7D,GAAI,CAAC,IAAI,CAAC,MAAM,CAAE,OAAO,KACzB,GAAI,CACF,OAAO,MAAM,IAAI,CAAC,MAAM,CAA+B,yBACzD,CAAE,KAAM,CACN,OAAO,IACT,CACF,CAKA,aAAa,uBAA0D,CACrE,IAAMC,EAAS7E,IACf,GAAI,CAAC6E,EAAQ,MAAO,EAAE,CACtB,GAAI,CACF,OAAO,MAAMA,EAAgC,+BAC/C,CAAE,KAAM,CACN,MAAO,EAAE,AACX,CACF,CA/UA,YAAYC,EAA4B,CAAC,CAAC,CAAE,CAC1C,KAAK,CAACA,GATR,aAAQ,eAAe,IACvB,aAAQ,cAAR,QACA,aAAQ,YAAR,QACA,aAAQ,UAAR,QACA,aAAQ,SAA+B,MACvC,aAAQ,aAAR,QACA,aAAQ,oBAAR,QAIE,IAAI,CAAC,YAAY,CAAGC,EAAQD,EAAO,KAAK,CACxC,IAAI,CAAC,WAAW,CAAGA,EAAO,WAAW,CACrC,IAAI,CAAC,SAAS,CAAGA,EAAO,SAAS,CACjC,IAAI,CAAC,OAAO,CAAGA,EAAO,OAAO,CAC7B,IAAI,CAAC,UAAU,CAAGA,EAAO,UAAU,CACnC,IAAI,CAAC,iBAAiB,CAAGA,EAAO,iBAAiB,EAAI,OAGrD,IAAI,CAAC,MAAM,CAAG9E,GAChB,CAqUF,C"}